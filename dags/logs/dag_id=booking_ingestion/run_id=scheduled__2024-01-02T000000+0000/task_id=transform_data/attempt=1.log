[2024-01-03T02:23:30.451+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T02:23:30.467+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T02:23:30.467+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-03T02:23:30.589+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T02:23:30.596+0000] {standard_task_runner.py:57} INFO - Started process 206 to run task
[2024-01-03T02:23:30.601+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '61', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator2.py', '--cfg-path', '/tmp/tmp60hx6o7a']
[2024-01-03T02:23:30.607+0000] {standard_task_runner.py:85} INFO - Job 61: Subtask transform_data
[2024-01-03T02:23:30.749+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-03T02:23:31.813+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T02:23:32.750+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgress_operator2.py:47 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T02:23:32.968+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T02:23:33.012+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T022330, end_date=20240103T022333
[2024-01-03T02:23:33.202+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T02:23:33.288+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T08:18:49.465+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T08:18:49.537+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T08:18:49.566+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-03T08:18:50.139+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T08:18:50.221+0000] {standard_task_runner.py:57} INFO - Started process 570 to run task
[2024-01-03T08:18:50.437+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '67', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator1.py', '--cfg-path', '/tmp/tmp2crssz0f']
[2024-01-03T08:18:50.855+0000] {standard_task_runner.py:85} INFO - Job 67: Subtask transform_data
[2024-01-03T08:18:57.326+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-03T08:19:46.692+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T08:19:51.141+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgress_operator1.py:47 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T08:19:53.034+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T08:19:53.294+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T081849, end_date=20240103T081953
[2024-01-03T08:19:54.644+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T08:19:54.752+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-03T08:25:57.913+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T08:25:57.959+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T08:25:57.960+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-03T08:25:58.041+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T08:25:58.049+0000] {standard_task_runner.py:57} INFO - Started process 752 to run task
[2024-01-03T08:25:58.054+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '68', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator1.py', '--cfg-path', '/tmp/tmpmfd_2quy']
[2024-01-03T08:25:58.058+0000] {standard_task_runner.py:85} INFO - Job 68: Subtask transform_data
[2024-01-03T08:25:58.199+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-03T08:25:59.207+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T08:25:59.351+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgress_operator1.py:47 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T08:25:59.388+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T08:25:59.407+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T082557, end_date=20240103T082559
[2024-01-03T08:25:59.513+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T08:25:59.567+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T08:30:46.032+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T08:30:46.187+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T08:30:46.189+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-03T08:30:46.310+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T08:30:46.319+0000] {standard_task_runner.py:57} INFO - Started process 937 to run task
[2024-01-03T08:30:46.324+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '70', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator1.py', '--cfg-path', '/tmp/tmp4pz1__xh']
[2024-01-03T08:30:46.330+0000] {standard_task_runner.py:85} INFO - Job 70: Subtask transform_data
[2024-01-03T08:30:46.533+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-03T08:30:48.868+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T08:30:48.918+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgress_operator1.py:47 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T08:30:48.941+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T08:30:48.968+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T083046, end_date=20240103T083048
[2024-01-03T08:30:49.082+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T08:30:49.211+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-03T10:18:00.522+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T10:18:00.860+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T10:18:00.863+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-03T10:18:01.119+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T10:18:01.777+0000] {standard_task_runner.py:57} INFO - Started process 4945 to run task
[2024-01-03T10:18:04.508+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '74', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator1.py', '--cfg-path', '/tmp/tmp4d90tcee']
[2024-01-03T10:18:04.879+0000] {standard_task_runner.py:85} INFO - Job 74: Subtask transform_data
[2024-01-03T10:18:06.641+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-03T10:18:10.236+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T10:18:11.779+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgress_operator1.py:47 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T10:18:12.027+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T10:18:12.529+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T101800, end_date=20240103T101812
[2024-01-03T10:18:12.700+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T10:18:12.769+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T10:49:36.642+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T10:49:36.673+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T10:49:36.673+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-03T10:49:36.759+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T10:49:36.871+0000] {standard_task_runner.py:57} INFO - Started process 6158 to run task
[2024-01-03T10:49:36.881+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '77', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator1.py', '--cfg-path', '/tmp/tmp961re0uw']
[2024-01-03T10:49:37.405+0000] {standard_task_runner.py:85} INFO - Job 77: Subtask transform_data
[2024-01-03T10:50:11.943+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-03T10:51:58.967+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T10:52:01.643+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgress_operator1.py:47 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T10:52:01.982+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T10:52:02.435+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T104936, end_date=20240103T105202
[2024-01-03T10:52:04.074+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T10:52:04.319+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T11:55:59.338+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T11:55:59.365+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T11:55:59.366+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-03T11:55:59.442+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T11:55:59.450+0000] {standard_task_runner.py:57} INFO - Started process 8610 to run task
[2024-01-03T11:55:59.454+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '80', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator1.py', '--cfg-path', '/tmp/tmprvrcv90y']
[2024-01-03T11:55:59.458+0000] {standard_task_runner.py:85} INFO - Job 80: Subtask transform_data
[2024-01-03T11:55:59.578+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-03T11:55:59.908+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T11:55:59.943+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgress_operator1.py:47 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T11:55:59.958+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T11:55:59.976+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T115559, end_date=20240103T115559
[2024-01-03T11:56:00.029+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T11:56:00.069+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T12:00:59.346+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T12:00:59.360+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T12:00:59.360+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-03T12:00:59.420+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T12:00:59.427+0000] {standard_task_runner.py:57} INFO - Started process 8827 to run task
[2024-01-03T12:00:59.431+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '83', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator1.py', '--cfg-path', '/tmp/tmpqs6hsxgg']
[2024-01-03T12:00:59.434+0000] {standard_task_runner.py:85} INFO - Job 83: Subtask transform_data
[2024-01-03T12:00:59.523+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-03T12:00:59.957+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T12:01:00.005+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgress_operator1.py:47 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T12:01:00.038+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T12:01:00.057+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T120059, end_date=20240103T120100
[2024-01-03T12:01:00.126+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T12:01:00.180+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T14:18:50.962+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:18:50.982+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:18:50.983+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T14:18:51.019+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T14:18:51.026+0000] {standard_task_runner.py:57} INFO - Started process 1911 to run task
[2024-01-03T14:18:51.031+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '96', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmpxhx92874']
[2024-01-03T14:18:51.035+0000] {standard_task_runner.py:85} INFO - Job 96: Subtask transform_data
[2024-01-03T14:18:51.117+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 1aef81c6d4c5
[2024-01-03T14:18:51.556+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T14:18:54.907+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgres_operator.py:51 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T14:18:56.319+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T14:18:56.554+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T141850, end_date=20240103T141856
[2024-01-03T14:18:56.756+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T14:18:57.320+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-03T14:36:32.487+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:36:32.501+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:36:32.502+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T14:36:32.539+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T14:36:32.547+0000] {standard_task_runner.py:57} INFO - Started process 2436 to run task
[2024-01-03T14:36:32.553+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '100', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmph6tf0rrp']
[2024-01-03T14:36:32.557+0000] {standard_task_runner.py:85} INFO - Job 100: Subtask transform_data
[2024-01-03T14:36:32.686+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 1aef81c6d4c5
[2024-01-03T14:36:41.481+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T14:36:42.353+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgres_operator.py:51 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T14:36:43.368+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T14:36:43.415+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T143632, end_date=20240103T143643
[2024-01-03T14:36:43.962+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T14:36:44.852+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-03T14:39:24.230+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:39:24.243+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:39:24.243+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T14:39:24.286+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T14:39:24.304+0000] {standard_task_runner.py:57} INFO - Started process 2543 to run task
[2024-01-03T14:39:24.309+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '104', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmpgjt02992']
[2024-01-03T14:39:24.313+0000] {standard_task_runner.py:85} INFO - Job 104: Subtask transform_data
[2024-01-03T14:39:24.408+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 1aef81c6d4c5
[2024-01-03T14:39:24.775+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T14:39:24.854+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgres_operator.py:51 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T14:39:24.871+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T14:39:24.883+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T143924, end_date=20240103T143924
[2024-01-03T14:39:24.964+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T14:39:25.002+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T14:47:27.031+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:47:27.043+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:47:27.044+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T14:47:27.085+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T14:47:27.092+0000] {standard_task_runner.py:57} INFO - Started process 2776 to run task
[2024-01-03T14:47:27.096+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '108', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmpvsmk2e84']
[2024-01-03T14:47:27.101+0000] {standard_task_runner.py:85} INFO - Job 108: Subtask transform_data
[2024-01-03T14:47:27.188+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 1aef81c6d4c5
[2024-01-03T14:47:27.562+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T14:47:27.602+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgres_operator.py:51 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T14:47:27.621+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T14:47:27.634+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T144727, end_date=20240103T144727
[2024-01-03T14:47:27.751+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T14:47:27.788+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T14:49:39.945+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:49:39.958+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:49:39.959+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T14:49:40.004+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T14:49:40.012+0000] {standard_task_runner.py:57} INFO - Started process 2852 to run task
[2024-01-03T14:49:40.016+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '112', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmpjh3tg1dk']
[2024-01-03T14:49:40.020+0000] {standard_task_runner.py:85} INFO - Job 112: Subtask transform_data
[2024-01-03T14:49:40.110+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 1aef81c6d4c5
[2024-01-03T14:49:40.550+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T14:49:40.597+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgres_operator.py:51 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T14:49:40.622+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T14:49:40.637+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T144939, end_date=20240103T144940
[2024-01-03T14:49:40.714+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T14:49:40.754+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T14:53:28.635+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:53:28.649+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:53:28.650+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T14:53:28.782+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T14:53:28.790+0000] {standard_task_runner.py:57} INFO - Started process 2973 to run task
[2024-01-03T14:53:28.795+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '116', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmp5nyfw19t']
[2024-01-03T14:53:28.799+0000] {standard_task_runner.py:85} INFO - Job 116: Subtask transform_data
[2024-01-03T14:53:28.900+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 1aef81c6d4c5
[2024-01-03T14:53:29.250+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T14:53:30.045+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgres_operator.py:51 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T14:53:31.378+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T14:53:31.513+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T145328, end_date=20240103T145331
[2024-01-03T14:53:31.648+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T14:53:31.772+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-03T14:57:16.213+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:57:16.226+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:57:16.227+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T14:57:16.269+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T14:57:16.276+0000] {standard_task_runner.py:57} INFO - Started process 3110 to run task
[2024-01-03T14:57:16.281+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '120', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmp3139m71m']
[2024-01-03T14:57:16.284+0000] {standard_task_runner.py:85} INFO - Job 120: Subtask transform_data
[2024-01-03T14:57:16.362+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 1aef81c6d4c5
[2024-01-03T14:57:16.732+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T14:57:19.978+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgres_operator.py:51 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T14:57:20.373+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T14:57:20.632+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T145716, end_date=20240103T145720
[2024-01-03T14:57:20.946+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T14:57:20.991+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T15:01:33.530+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T15:01:33.544+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T15:01:33.545+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T15:01:33.741+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T15:01:33.750+0000] {standard_task_runner.py:57} INFO - Started process 3263 to run task
[2024-01-03T15:01:33.754+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '124', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmp3kwkj1hk']
[2024-01-03T15:01:33.759+0000] {standard_task_runner.py:85} INFO - Job 124: Subtask transform_data
[2024-01-03T15:01:34.016+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 1aef81c6d4c5
[2024-01-03T15:01:34.642+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T15:01:34.785+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgres_operator.py:51 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T15:01:34.803+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T15:01:34.815+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T150133, end_date=20240103T150134
[2024-01-03T15:01:34.931+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T15:01:34.968+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T15:04:39.567+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T15:04:39.581+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T15:04:39.582+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T15:04:39.822+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T15:04:39.828+0000] {standard_task_runner.py:57} INFO - Started process 3369 to run task
[2024-01-03T15:04:39.832+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '127', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmph2sl7skt']
[2024-01-03T15:04:39.836+0000] {standard_task_runner.py:85} INFO - Job 127: Subtask transform_data
[2024-01-03T15:04:39.944+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 1aef81c6d4c5
[2024-01-03T15:05:57.300+0000] {job.py:219} ERROR - Job heartbeat got an exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/jobs/job.py", line 215, in heartbeat
    heartbeat_callback(session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/jobs/local_task_job_runner.py", line 246, in heartbeat_callback
    self.task_instance.refresh_from_db()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 866, in refresh_from_db
    ti = qry.one_or_none()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2850, in one_or_none
    return self._iter().one_or_none()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-01-03T15:06:09.896+0000] {taskinstance.py:1943} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  the database system is in recovery mode


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1518, in _run_raw_task
    self._execute_task_with_callbacks(context, test_mode, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1650, in _execute_task_with_callbacks
    RenderedTaskInstanceFields.delete_old_records(self.task_id, self.dag_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/renderedtifields.py", line 218, in delete_old_records
    cls._do_delete_old_records(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/retries.py", line 90, in wrapped_function
    for attempt in run_with_db_retries(max_retries=retries, logger=logger, **retry_kwargs):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/retries.py", line 99, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/renderedtifields.py", line 250, in _do_delete_old_records
    session.execute(stmt)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  the database system is in recovery mode

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-01-03T15:06:15.027+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 127 for task transform_data ((psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  the database system is in recovery mode

(Background on this error at: https://sqlalche.me/e/14/e3q8); 3369)
[2024-01-03T15:06:14.993+0000] {job.py:219} ERROR - Job heartbeat got an exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  the database system is in recovery mode


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/jobs/job.py", line 190, in heartbeat
    session.merge(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3056, in merge
    return self._merge(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3136, in _merge
    merged = self.get(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 2853, in get
    return self._get_impl(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 2975, in _get_impl
    return db_load_fn(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/loading.py", line 530, in load_on_pk_identity
    session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  the database system is in recovery mode

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-01-03T15:06:15.701+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2024-01-03T15:06:16.324+0000] {taskinstance.py:2790} INFO - Skipping mini scheduling run due to exception: None
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  the database system is in recovery mode


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2739, in schedule_downstream_tasks
    dag_run = with_row_locks(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.18.0.2), port 5432 failed: FATAL:  the database system is in recovery mode

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-01-03T15:16:03.517+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T15:16:03.611+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T15:16:03.612+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T15:16:03.729+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T15:16:03.738+0000] {standard_task_runner.py:57} INFO - Started process 244 to run task
[2024-01-03T15:16:03.743+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '134', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmpa8m2cxwt']
[2024-01-03T15:16:03.748+0000] {standard_task_runner.py:85} INFO - Job 134: Subtask transform_data
[2024-01-03T15:16:03.886+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 1aef81c6d4c5
[2024-01-03T15:16:04.428+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T15:16:04.460+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgres_operator.py:51 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T15:16:04.477+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T15:16:04.489+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T151603, end_date=20240103T151604
[2024-01-03T15:16:04.560+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T15:16:04.661+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T15:33:54.771+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T15:33:54.804+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T15:33:54.805+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T15:33:54.854+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T15:33:54.862+0000] {standard_task_runner.py:57} INFO - Started process 196 to run task
[2024-01-03T15:33:54.869+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '140', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmpuwbyd8m0']
[2024-01-03T15:33:54.872+0000] {standard_task_runner.py:85} INFO - Job 140: Subtask transform_data
[2024-01-03T15:33:54.980+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 1aef81c6d4c5
[2024-01-03T15:33:55.730+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T15:33:55.917+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgres_operator.py:51 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T15:33:56.085+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T15:33:56.113+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T153354, end_date=20240103T153356
[2024-01-03T15:33:56.218+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T15:33:56.270+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T15:41:15.494+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T15:41:15.548+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T15:41:15.549+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T15:41:15.629+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T15:41:15.646+0000] {standard_task_runner.py:57} INFO - Started process 387 to run task
[2024-01-03T15:41:16.343+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '144', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmpnp91eyhe']
[2024-01-03T15:41:19.370+0000] {standard_task_runner.py:85} INFO - Job 144: Subtask transform_data
[2024-01-03T15:41:39.183+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 1aef81c6d4c5
[2024-01-03T15:43:24.841+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T15:43:36.515+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgres_operator.py:51 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T15:43:37.104+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T15:43:40.967+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T154115, end_date=20240103T154340
[2024-01-03T15:43:43.055+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T15:43:43.118+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T17:40:45.389+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T17:40:45.462+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T17:40:47.715+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T17:40:47.716+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T17:40:47.763+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T17:40:47.776+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T17:40:47.777+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T17:40:48.088+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T17:40:48.194+0000] {standard_task_runner.py:57} INFO - Started process 181 to run task
[2024-01-03T17:40:48.197+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmpr7timr95']
[2024-01-03T17:40:48.702+0000] {standard_task_runner.py:85} INFO - Job 5: Subtask transform_data
[2024-01-03T17:40:49.045+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T17:40:49.045+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T17:40:49.048+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 7bf68de21308
[2024-01-03T17:40:50.654+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T17:40:59.524+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgres_operator.py:48 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T17:41:00.723+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T17:41:00.736+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T174047, end_date=20240103T174100
[2024-01-03T17:41:01.176+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T17:41:01.367+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T17:46:29.055+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T17:46:29.057+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T17:46:29.158+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T17:46:29.160+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T17:46:29.244+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T17:46:29.263+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T17:46:29.264+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T17:46:29.562+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T17:46:29.570+0000] {standard_task_runner.py:57} INFO - Started process 335 to run task
[2024-01-03T17:46:29.574+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmp1fyqjn1t']
[2024-01-03T17:46:29.577+0000] {standard_task_runner.py:85} INFO - Job 8: Subtask transform_data
[2024-01-03T17:46:29.728+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T17:46:29.729+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T17:46:29.731+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 7bf68de21308
[2024-01-03T17:46:30.151+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T17:46:30.191+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgres_operator.py:48 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T17:46:30.208+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T17:46:30.220+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T174629, end_date=20240103T174630
[2024-01-03T17:46:30.309+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T17:46:30.348+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T18:13:21.249+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T18:13:21.263+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T18:13:21.379+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T18:13:21.380+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T18:13:21.529+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T18:13:21.550+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T18:13:21.552+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T18:13:21.610+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T18:13:21.628+0000] {standard_task_runner.py:57} INFO - Started process 996 to run task
[2024-01-03T18:13:21.638+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '11', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmp0i2xztmk']
[2024-01-03T18:13:21.646+0000] {standard_task_runner.py:85} INFO - Job 11: Subtask transform_data
[2024-01-03T18:13:21.752+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T18:13:21.754+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T18:13:21.757+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 7bf68de21308
[2024-01-03T18:13:40.851+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T18:13:41.511+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgres_operator.py:48 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T18:13:41.665+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T18:13:42.293+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T181321, end_date=20240103T181342
[2024-01-03T18:13:42.469+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T18:13:42.512+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T19:49:07.467+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T19:49:07.490+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T19:49:07.711+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T19:49:07.712+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T19:49:08.045+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T19:49:08.060+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T19:49:08.061+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T19:49:08.181+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T19:49:08.188+0000] {standard_task_runner.py:57} INFO - Started process 3426 to run task
[2024-01-03T19:49:08.194+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '19', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmp6t6wwm55']
[2024-01-03T19:49:08.198+0000] {standard_task_runner.py:85} INFO - Job 19: Subtask transform_data
[2024-01-03T19:49:08.285+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T19:49:08.286+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T19:49:08.288+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 7bf68de21308
[2024-01-03T19:49:08.739+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T19:49:09.400+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgres_operator.py:48 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T19:49:09.803+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T19:49:09.822+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T194908, end_date=20240103T194909
[2024-01-03T19:49:09.894+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T19:49:09.934+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T19:53:21.494+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T19:53:21.495+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T19:53:21.603+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T19:53:21.604+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T19:53:21.674+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T19:53:21.688+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T19:53:21.689+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T19:53:21.751+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T19:53:21.769+0000] {standard_task_runner.py:57} INFO - Started process 3553 to run task
[2024-01-03T19:53:21.774+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmpu9px0y4h']
[2024-01-03T19:53:21.777+0000] {standard_task_runner.py:85} INFO - Job 22: Subtask transform_data
[2024-01-03T19:53:21.872+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T19:53:21.873+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T19:53:21.875+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 7bf68de21308
[2024-01-03T19:53:22.265+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T19:53:22.312+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgres_operator.py:48 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T19:53:22.354+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T19:53:22.368+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T195321, end_date=20240103T195322
[2024-01-03T19:53:22.469+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T19:53:22.525+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-03T19:59:34.770+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T19:59:34.771+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T19:59:34.863+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T19:59:34.864+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T19:59:35.007+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T19:59:35.037+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T19:59:35.038+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T19:59:35.211+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T19:59:35.273+0000] {standard_task_runner.py:57} INFO - Started process 3752 to run task
[2024-01-03T19:59:35.279+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '26', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmpthxsz27q']
[2024-01-03T19:59:35.283+0000] {standard_task_runner.py:85} INFO - Job 26: Subtask transform_data
[2024-01-03T19:59:35.421+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T19:59:35.422+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T19:59:35.428+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 7bf68de21308
[2024-01-03T19:59:35.844+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T19:59:35.882+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgres_operator.py:48 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T19:59:35.898+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T19:59:35.910+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T195935, end_date=20240103T195935
[2024-01-03T19:59:35.975+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T19:59:36.009+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T20:03:30.139+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T20:03:30.139+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T20:03:30.209+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T20:03:30.210+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T20:03:30.319+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T20:03:30.334+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T20:03:30.335+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T20:03:30.392+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T20:03:30.400+0000] {standard_task_runner.py:57} INFO - Started process 3878 to run task
[2024-01-03T20:03:30.405+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '29', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmp5u_ppnuz']
[2024-01-03T20:03:30.408+0000] {standard_task_runner.py:85} INFO - Job 29: Subtask transform_data
[2024-01-03T20:03:30.497+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T20:03:30.497+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T20:03:30.500+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 7bf68de21308
[2024-01-03T20:03:30.891+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T20:03:30.952+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgres_operator.py:48 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T20:03:30.970+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T20:03:30.983+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T200330, end_date=20240103T200330
[2024-01-03T20:03:31.059+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T20:03:31.107+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T20:05:08.886+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T20:05:08.887+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T20:05:08.948+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T20:05:08.949+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T20:05:08.997+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T20:05:09.015+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T20:05:09.016+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T20:05:09.059+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T20:05:09.068+0000] {standard_task_runner.py:57} INFO - Started process 3931 to run task
[2024-01-03T20:05:09.074+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '32', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmp78711a0z']
[2024-01-03T20:05:09.079+0000] {standard_task_runner.py:85} INFO - Job 32: Subtask transform_data
[2024-01-03T20:05:09.186+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T20:05:09.187+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T20:05:09.190+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 7bf68de21308
[2024-01-03T20:05:09.642+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T20:05:09.703+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgres_operator.py:49 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T20:05:09.736+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T20:05:09.763+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T200508, end_date=20240103T200509
[2024-01-03T20:05:09.854+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T20:05:09.890+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T20:11:05.277+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T20:11:05.279+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T20:11:05.345+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T20:11:05.345+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T20:11:05.416+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T20:11:05.429+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T20:11:05.431+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T20:11:05.484+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T20:11:05.493+0000] {standard_task_runner.py:57} INFO - Started process 4102 to run task
[2024-01-03T20:11:05.500+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '36', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmpi68qdhcn']
[2024-01-03T20:11:05.505+0000] {standard_task_runner.py:85} INFO - Job 36: Subtask transform_data
[2024-01-03T20:11:05.600+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T20:11:05.602+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T20:11:05.604+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 7bf68de21308
[2024-01-03T20:11:06.056+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T20:11:06.245+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgres_operator.py:49 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T20:11:06.266+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T20:11:06.281+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T201105, end_date=20240103T201106
[2024-01-03T20:11:06.357+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T20:11:06.418+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T20:17:20.277+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T20:17:20.278+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T20:17:20.357+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T20:17:20.359+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T20:17:20.459+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T20:17:20.479+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T20:17:20.480+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T20:17:20.525+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): transform_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T20:17:20.532+0000] {standard_task_runner.py:57} INFO - Started process 4300 to run task
[2024-01-03T20:17:20.537+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'transform_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '40', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmpw0moq2qv']
[2024-01-03T20:17:20.541+0000] {standard_task_runner.py:85} INFO - Job 40: Subtask transform_data
[2024-01-03T20:17:20.644+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509
[2024-01-03T20:17:20.646+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=transform_data'
[2024-01-03T20:17:20.649+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.transform_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 7bf68de21308
[2024-01-03T20:17:21.082+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='transform_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T20:17:21.120+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgres_operator.py:53 UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.
[2024-01-03T20:17:21.138+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T20:17:21.151+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=transform_data, execution_date=20240102T000000, start_date=20240103T201720, end_date=20240103T201721
[2024-01-03T20:17:21.272+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T20:17:21.310+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
