[2024-01-03T02:23:42.083+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T02:23:42.098+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T02:23:42.099+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-03T02:23:42.219+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T02:23:42.252+0000] {standard_task_runner.py:57} INFO - Started process 212 to run task
[2024-01-03T02:23:42.274+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '63', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator2.py', '--cfg-path', '/tmp/tmpmrb9pl82']
[2024-01-03T02:23:42.284+0000] {standard_task_runner.py:85} INFO - Job 63: Subtask load_data
[2024-01-03T02:23:42.477+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-03T02:23:42.913+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T02:23:49.840+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T02:23:49.889+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=load_data, execution_date=20240102T000000, start_date=20240103T022342, end_date=20240103T022349
[2024-01-03T02:23:50.028+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T02:23:50.085+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T08:30:57.445+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T08:30:57.492+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T08:30:57.493+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-03T08:30:57.559+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T08:30:57.570+0000] {standard_task_runner.py:57} INFO - Started process 952 to run task
[2024-01-03T08:30:57.576+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '72', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator1.py', '--cfg-path', '/tmp/tmpufq_v_2k']
[2024-01-03T08:30:57.599+0000] {standard_task_runner.py:85} INFO - Job 72: Subtask load_data
[2024-01-03T08:30:57.785+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-03T08:30:58.370+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T08:31:01.100+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T08:31:01.123+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=load_data, execution_date=20240102T000000, start_date=20240103T083057, end_date=20240103T083101
[2024-01-03T08:31:01.323+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T08:31:01.521+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-03T10:18:27.581+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T10:18:27.669+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T10:18:27.670+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-03T10:18:27.770+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T10:18:27.826+0000] {standard_task_runner.py:57} INFO - Started process 4954 to run task
[2024-01-03T10:18:27.851+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '76', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator1.py', '--cfg-path', '/tmp/tmp4ja3pu28']
[2024-01-03T10:18:27.892+0000] {standard_task_runner.py:85} INFO - Job 76: Subtask load_data
[2024-01-03T10:18:28.063+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-03T10:18:28.925+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T10:18:28.973+0000] {base.py:73} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-01-03T10:18:29.245+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgress_operator1.py:87 UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
[2024-01-03T10:18:29.319+0000] {taskinstance.py:1943} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2202, in execute
    cur.execute(sql, *args)
psycopg2.errors.UndefinedTable: relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 221, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag_with_postgress_operator1.py", line 87, in load_data
    records.to_sql("booking_record", con=conn, if_exists='replace',index_label='id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 2878, in to_sql
    return sql.to_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 769, in to_sql
    return pandas_sql.to_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2378, in to_sql
    table.create()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 903, in create
    if self.exists():
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 889, in exists
    return self.pd_sql.has_table(self.name, self.schema)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2385, in has_table
    return len(self.execute(query, [name]).fetchall()) > 0
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2214, in execute
    raise ex from exc
pandas.errors.DatabaseError: Execution failed on sql 'SELECT name FROM sqlite_master WHERE type='table' AND name=?;': relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^

[2024-01-03T10:18:29.927+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=booking_ingestion, task_id=load_data, execution_date=20240102T000000, start_date=20240103T101827, end_date=20240103T101829
[2024-01-03T10:18:30.455+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 76 for task load_data (Execution failed on sql 'SELECT name FROM sqlite_master WHERE type='table' AND name=?;': relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^
; 4954)
[2024-01-03T10:18:30.521+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2024-01-03T10:18:30.564+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-03T10:52:39.344+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T10:52:39.381+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T10:52:39.382+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-03T10:52:39.454+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T10:52:39.464+0000] {standard_task_runner.py:57} INFO - Started process 6207 to run task
[2024-01-03T10:52:39.470+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '79', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator1.py', '--cfg-path', '/tmp/tmpe9ubftu7']
[2024-01-03T10:52:39.476+0000] {standard_task_runner.py:85} INFO - Job 79: Subtask load_data
[2024-01-03T10:52:39.603+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-03T10:52:39.986+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T10:52:40.009+0000] {base.py:73} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-01-03T10:52:40.117+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgress_operator1.py:87 UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
[2024-01-03T10:52:40.151+0000] {taskinstance.py:1943} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2202, in execute
    cur.execute(sql, *args)
psycopg2.errors.UndefinedTable: relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 221, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag_with_postgress_operator1.py", line 87, in load_data
    records.to_sql("booking_record", con=conn, if_exists='replace',index_label='id',schema='test')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 2878, in to_sql
    return sql.to_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 769, in to_sql
    return pandas_sql.to_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2378, in to_sql
    table.create()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 903, in create
    if self.exists():
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 889, in exists
    return self.pd_sql.has_table(self.name, self.schema)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2385, in has_table
    return len(self.execute(query, [name]).fetchall()) > 0
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2214, in execute
    raise ex from exc
pandas.errors.DatabaseError: Execution failed on sql 'SELECT name FROM sqlite_master WHERE type='table' AND name=?;': relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^

[2024-01-03T10:52:40.347+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=booking_ingestion, task_id=load_data, execution_date=20240102T000000, start_date=20240103T105239, end_date=20240103T105240
[2024-01-03T10:52:40.394+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 79 for task load_data (Execution failed on sql 'SELECT name FROM sqlite_master WHERE type='table' AND name=?;': relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^
; 6207)
[2024-01-03T10:52:40.409+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2024-01-03T10:52:40.439+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-03T11:56:05.903+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T11:56:05.943+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T11:56:05.944+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-03T11:56:05.984+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T11:56:05.991+0000] {standard_task_runner.py:57} INFO - Started process 8616 to run task
[2024-01-03T11:56:05.996+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '82', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator1.py', '--cfg-path', '/tmp/tmpi2m104fr']
[2024-01-03T11:56:05.999+0000] {standard_task_runner.py:85} INFO - Job 82: Subtask load_data
[2024-01-03T11:56:06.094+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-03T11:56:06.518+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T11:56:06.562+0000] {base.py:73} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-01-03T11:56:06.622+0000] {base.py:73} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-01-03T11:56:06.631+0000] {taskinstance.py:1943} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 121, in connect
    dsn = _ext.make_dsn(dsn, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/extensions.py", line 167, in make_dsn
    parse_dsn(dsn)
psycopg2.ProgrammingError: invalid dsn: invalid connection option "__extra__"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 221, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag_with_postgress_operator1.py", line 87, in load_data
    records.to_sql("booking_record", postgres_hook.get_sqlalchemy_engine(), if_exists='replace',index_label='id')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 2878, in to_sql
    return sql.to_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 768, in to_sql
    with pandasSQL_builder(con, schema=schema, need_transaction=True) as pandas_sql:
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 832, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1539, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 121, in connect
    dsn = _ext.make_dsn(dsn, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/extensions.py", line 167, in make_dsn
    parse_dsn(dsn)
sqlalchemy.exc.ProgrammingError: (psycopg2.ProgrammingError) invalid dsn: invalid connection option "__extra__"

(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-01-03T11:56:06.721+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=booking_ingestion, task_id=load_data, execution_date=20240102T000000, start_date=20240103T115605, end_date=20240103T115606
[2024-01-03T11:56:06.799+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 82 for task load_data ((psycopg2.ProgrammingError) invalid dsn: invalid connection option "__extra__"

(Background on this error at: https://sqlalche.me/e/14/f405); 8616)
[2024-01-03T11:56:06.862+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2024-01-03T11:56:06.949+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-03T12:01:06.965+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T12:01:06.981+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T12:01:06.982+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-03T12:01:07.025+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T12:01:07.033+0000] {standard_task_runner.py:57} INFO - Started process 8833 to run task
[2024-01-03T12:01:07.037+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '85', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator1.py', '--cfg-path', '/tmp/tmpq888769z']
[2024-01-03T12:01:07.041+0000] {standard_task_runner.py:85} INFO - Job 85: Subtask load_data
[2024-01-03T12:01:07.139+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-03T12:01:07.592+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T12:01:07.615+0000] {base.py:73} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-01-03T12:01:07.621+0000] {taskinstance.py:1943} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 121, in connect
    dsn = _ext.make_dsn(dsn, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/extensions.py", line 167, in make_dsn
    parse_dsn(dsn)
psycopg2.ProgrammingError: invalid dsn: invalid connection option "__extra__"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 221, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag_with_postgress_operator1.py", line 87, in load_data
    records.to_sql("booking_record", con=engine, if_exists='replace',index_label='id',schema='test')
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 2878, in to_sql
    return sql.to_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 768, in to_sql
    with pandasSQL_builder(con, schema=schema, need_transaction=True) as pandas_sql:
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 832, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 1539, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 121, in connect
    dsn = _ext.make_dsn(dsn, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/extensions.py", line 167, in make_dsn
    parse_dsn(dsn)
sqlalchemy.exc.ProgrammingError: (psycopg2.ProgrammingError) invalid dsn: invalid connection option "__extra__"

(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-01-03T12:01:07.641+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=booking_ingestion, task_id=load_data, execution_date=20240102T000000, start_date=20240103T120106, end_date=20240103T120107
[2024-01-03T12:01:07.678+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 85 for task load_data ((psycopg2.ProgrammingError) invalid dsn: invalid connection option "__extra__"

(Background on this error at: https://sqlalche.me/e/14/f405); 8833)
[2024-01-03T12:01:07.693+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2024-01-03T12:01:07.723+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-03T14:19:07.467+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:19:07.489+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:19:07.489+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T14:19:07.536+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T14:19:07.544+0000] {standard_task_runner.py:57} INFO - Started process 1928 to run task
[2024-01-03T14:19:07.550+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '98', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmpstjod03e']
[2024-01-03T14:19:07.554+0000] {standard_task_runner.py:85} INFO - Job 98: Subtask load_data
[2024-01-03T14:19:07.644+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 1aef81c6d4c5
[2024-01-03T14:19:08.064+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T14:19:08.075+0000] {python.py:194} INFO - Done. Returned value was: {'status': 'error', 'message': "'str' object has no attribute 'keys'"}
[2024-01-03T14:19:08.123+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=load_data, execution_date=20240102T000000, start_date=20240103T141907, end_date=20240103T141908
[2024-01-03T14:19:08.205+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T14:19:08.235+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T14:37:22.091+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:37:22.107+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:37:22.108+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T14:37:22.255+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T14:37:22.271+0000] {standard_task_runner.py:57} INFO - Started process 2468 to run task
[2024-01-03T14:37:22.275+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '102', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmpzn38cto0']
[2024-01-03T14:37:22.279+0000] {standard_task_runner.py:85} INFO - Job 102: Subtask load_data
[2024-01-03T14:37:22.768+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 1aef81c6d4c5
[2024-01-03T14:37:23.477+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T14:37:23.799+0000] {python.py:194} INFO - Done. Returned value was: {'status': 'error', 'message': 'syntax error at or near "%"\nLINE 1: ...ge, client_name, client_type, hotel_name) VALUES (%s, %s, %s...\n                                                             ^\n'}
[2024-01-03T14:37:23.892+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=load_data, execution_date=20240102T000000, start_date=20240103T143722, end_date=20240103T143723
[2024-01-03T14:37:23.970+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T14:37:24.005+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T14:39:30.747+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:39:30.761+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:39:30.762+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T14:39:30.806+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T14:39:30.814+0000] {standard_task_runner.py:57} INFO - Started process 2549 to run task
[2024-01-03T14:39:30.819+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '106', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmptxa0owqt']
[2024-01-03T14:39:30.822+0000] {standard_task_runner.py:85} INFO - Job 106: Subtask load_data
[2024-01-03T14:39:30.900+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 1aef81c6d4c5
[2024-01-03T14:39:31.267+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T14:39:31.582+0000] {python.py:194} INFO - Done. Returned value was: {'status': 'error', 'message': 'integer out of range\n'}
[2024-01-03T14:39:31.662+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=load_data, execution_date=20240102T000000, start_date=20240103T143930, end_date=20240103T143931
[2024-01-03T14:39:31.756+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T14:39:31.793+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T14:47:32.756+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:47:32.774+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:47:32.774+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T14:47:32.863+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T14:47:32.872+0000] {standard_task_runner.py:57} INFO - Started process 2782 to run task
[2024-01-03T14:47:32.877+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '110', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmpa8wtfoj1']
[2024-01-03T14:47:32.881+0000] {standard_task_runner.py:85} INFO - Job 110: Subtask load_data
[2024-01-03T14:47:32.986+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 1aef81c6d4c5
[2024-01-03T14:47:43.991+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T14:47:48.833+0000] {python.py:194} INFO - Done. Returned value was: {'status': 'error', 'message': 'relation "booking_record" does not exist\nLINE 1: INSERT INTO booking_record(client_id, booking_date, room_typ...\n                    ^\n'}
[2024-01-03T14:47:49.848+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=load_data, execution_date=20240102T000000, start_date=20240103T144732, end_date=20240103T144749
[2024-01-03T14:47:50.147+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T14:47:50.180+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T14:49:47.692+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:49:47.707+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:49:47.708+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T14:49:47.752+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T14:49:47.777+0000] {standard_task_runner.py:57} INFO - Started process 2858 to run task
[2024-01-03T14:49:47.783+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '114', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmp8jygyiuy']
[2024-01-03T14:49:47.795+0000] {standard_task_runner.py:85} INFO - Job 114: Subtask load_data
[2024-01-03T14:49:47.907+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 1aef81c6d4c5
[2024-01-03T14:49:48.356+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T14:49:48.392+0000] {python.py:194} INFO - Done. Returned value was: {'status': 'error', 'message': 'integer out of range\n'}
[2024-01-03T14:49:48.505+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=load_data, execution_date=20240102T000000, start_date=20240103T144947, end_date=20240103T144948
[2024-01-03T14:49:48.607+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T14:49:48.643+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T14:53:37.446+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:53:37.464+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:53:37.465+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T14:53:37.538+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T14:53:37.545+0000] {standard_task_runner.py:57} INFO - Started process 2979 to run task
[2024-01-03T14:53:37.549+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '118', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmp8t7c50hc']
[2024-01-03T14:53:37.553+0000] {standard_task_runner.py:85} INFO - Job 118: Subtask load_data
[2024-01-03T14:53:37.633+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 1aef81c6d4c5
[2024-01-03T14:53:37.986+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T14:53:37.998+0000] {python.py:194} INFO - Done. Returned value was: {'status': 'error', 'message': "'numpy.ndarray' object is not callable"}
[2024-01-03T14:53:38.060+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=load_data, execution_date=20240102T000000, start_date=20240103T145337, end_date=20240103T145338
[2024-01-03T14:53:38.124+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T14:53:38.157+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T14:57:28.059+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:57:28.073+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T14:57:28.074+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T14:57:28.109+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T14:57:28.117+0000] {standard_task_runner.py:57} INFO - Started process 3124 to run task
[2024-01-03T14:57:28.124+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '122', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmpcxu6l_zp']
[2024-01-03T14:57:28.128+0000] {standard_task_runner.py:85} INFO - Job 122: Subtask load_data
[2024-01-03T14:57:28.219+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 1aef81c6d4c5
[2024-01-03T14:57:28.673+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T14:57:28.713+0000] {logging_mixin.py:151} INFO - Error: integer out of range
[2024-01-03T14:57:28.717+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T14:57:28.734+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=load_data, execution_date=20240102T000000, start_date=20240103T145728, end_date=20240103T145728
[2024-01-03T14:57:28.860+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T14:57:28.889+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T15:01:40.164+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T15:01:40.177+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T15:01:40.177+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T15:01:40.221+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T15:01:40.228+0000] {standard_task_runner.py:57} INFO - Started process 3275 to run task
[2024-01-03T15:01:40.234+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '126', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmpc5f0wu85']
[2024-01-03T15:01:40.238+0000] {standard_task_runner.py:85} INFO - Job 126: Subtask load_data
[2024-01-03T15:01:40.332+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 1aef81c6d4c5
[2024-01-03T15:01:40.730+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T15:01:40.765+0000] {taskinstance.py:1943} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/opt/airflow/dags/dag_with_postgres_operator.py", line 100, in load_data
    cursor.execute(insert_statement, tuple(row.values))
psycopg2.errors.NumericValueOutOfRange: integer out of range


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 221, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag_with_postgres_operator.py", line 103, in load_data
    except Error as e:
NameError: name 'Error' is not defined
[2024-01-03T15:01:40.813+0000] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=booking_ingestion, task_id=load_data, execution_date=20240102T000000, start_date=20240103T150140, end_date=20240103T150140
[2024-01-03T15:01:41.135+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 126 for task load_data (name 'Error' is not defined; 3275)
[2024-01-03T15:01:41.172+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2024-01-03T15:01:41.203+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-03T15:14:13.343+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T15:14:13.367+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T15:14:13.368+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T15:14:13.418+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T15:14:13.425+0000] {standard_task_runner.py:57} INFO - Started process 186 to run task
[2024-01-03T15:14:13.430+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '132', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmp1now2fy3']
[2024-01-03T15:14:13.434+0000] {standard_task_runner.py:85} INFO - Job 132: Subtask load_data
[2024-01-03T15:14:13.516+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 1aef81c6d4c5
[2024-01-03T15:14:13.918+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T15:14:13.960+0000] {logging_mixin.py:151} INFO - Error: integer out of range
[2024-01-03T15:14:13.963+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T15:14:13.985+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=load_data, execution_date=20240102T000000, start_date=20240103T151413, end_date=20240103T151413
[2024-01-03T15:14:14.045+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T15:14:14.081+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T15:16:09.874+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T15:16:09.909+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T15:16:09.910+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T15:16:09.991+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T15:16:10.001+0000] {standard_task_runner.py:57} INFO - Started process 250 to run task
[2024-01-03T15:16:10.008+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '136', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmpu50pvwnm']
[2024-01-03T15:16:10.015+0000] {standard_task_runner.py:85} INFO - Job 136: Subtask load_data
[2024-01-03T15:16:10.125+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 1aef81c6d4c5
[2024-01-03T15:16:10.624+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T15:16:10.681+0000] {logging_mixin.py:151} INFO - Error: integer out of range
[2024-01-03T15:16:10.687+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T15:16:10.726+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=load_data, execution_date=20240102T000000, start_date=20240103T151609, end_date=20240103T151610
[2024-01-03T15:16:10.826+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T15:16:10.859+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T15:34:02.839+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T15:34:02.857+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T15:34:02.857+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T15:34:02.903+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T15:34:02.910+0000] {standard_task_runner.py:57} INFO - Started process 210 to run task
[2024-01-03T15:34:02.917+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '142', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmpy1loi3rk']
[2024-01-03T15:34:02.920+0000] {standard_task_runner.py:85} INFO - Job 142: Subtask load_data
[2024-01-03T15:34:03.020+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 1aef81c6d4c5
[2024-01-03T15:34:03.491+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T15:34:03.597+0000] {logging_mixin.py:151} INFO - Error: integer out of range
[2024-01-03T15:34:03.602+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T15:34:03.625+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=load_data, execution_date=20240102T000000, start_date=20240103T153402, end_date=20240103T153403
[2024-01-03T15:34:03.694+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T15:34:03.763+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T18:14:12.255+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509
[2024-01-03T18:14:12.273+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data'
[2024-01-03T18:14:12.423+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509
[2024-01-03T18:14:12.424+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data'
[2024-01-03T18:14:12.498+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T18:14:12.516+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T18:14:12.517+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T18:14:12.625+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T18:14:12.654+0000] {standard_task_runner.py:57} INFO - Started process 1022 to run task
[2024-01-03T18:14:12.659+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '13', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmp3i6oo4sh']
[2024-01-03T18:14:12.662+0000] {standard_task_runner.py:85} INFO - Job 13: Subtask load_data
[2024-01-03T18:14:12.816+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509
[2024-01-03T18:14:12.822+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data'
[2024-01-03T18:14:12.825+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 7bf68de21308
[2024-01-03T18:14:13.899+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T18:14:13.943+0000] {base.py:73} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-01-03T18:14:14.111+0000] {taskinstance.py:1943} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 221, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag_with_postgres_operator.py", line 93, in load_data
    cursor.execute(insert_data_query,tuple(row.values))
psycopg2.errors.NumericValueOutOfRange: integer out of range

[2024-01-03T18:14:14.583+0000] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=booking_ingestion, task_id=load_data, execution_date=20240102T000000, start_date=20240103T181412, end_date=20240103T181414
[2024-01-03T18:14:14.769+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 13 for task load_data (integer out of range
; 1022)
[2024-01-03T18:14:14.864+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2024-01-03T18:14:14.916+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-03T19:49:17.952+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509
[2024-01-03T19:49:17.970+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data'
[2024-01-03T19:49:18.075+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509
[2024-01-03T19:49:18.076+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data'
[2024-01-03T19:49:18.154+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T19:49:18.168+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T19:49:18.169+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T19:49:18.208+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T19:49:18.216+0000] {standard_task_runner.py:57} INFO - Started process 3445 to run task
[2024-01-03T19:49:18.221+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '21', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmp4ikp3n4j']
[2024-01-03T19:49:18.225+0000] {standard_task_runner.py:85} INFO - Job 21: Subtask load_data
[2024-01-03T19:49:18.374+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509
[2024-01-03T19:49:18.376+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data'
[2024-01-03T19:49:18.380+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 7bf68de21308
[2024-01-03T19:49:18.795+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T19:49:18.825+0000] {base.py:73} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-01-03T19:49:18.950+0000] {logging_mixin.py:151} INFO - INSERT INTO booking_record VALUES (4, 2016-11-02, first_class_2_bed, 6, 3140.0, GBP, 43.0, Bianca, VIP, The New View);
[2024-01-03T19:49:19.045+0000] {taskinstance.py:1943} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 221, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag_with_postgres_operator.py", line 95, in load_data
    cursor.execute(f"INSERT INTO booking_record VALUES ({', '.join([str(val) for val in row_dict.values()])});")
psycopg2.errors.SyntaxError: syntax error at or near "New"
LINE 1: ...ass_2_bed, 6, 3140.0, GBP, 43.0, Bianca, VIP, The New View);
                                                             ^

[2024-01-03T19:49:19.070+0000] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=booking_ingestion, task_id=load_data, execution_date=20240102T000000, start_date=20240103T194918, end_date=20240103T194919
[2024-01-03T19:49:19.149+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 21 for task load_data (syntax error at or near "New"
LINE 1: ...ass_2_bed, 6, 3140.0, GBP, 43.0, Bianca, VIP, The New View);
                                                             ^
; 3445)
[2024-01-03T19:49:19.198+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2024-01-03T19:49:19.280+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-03T19:53:26.618+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509
[2024-01-03T19:53:26.620+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data'
[2024-01-03T19:53:26.684+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509
[2024-01-03T19:53:26.685+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data'
[2024-01-03T19:53:26.750+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T19:53:26.768+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T19:53:26.768+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T19:53:26.824+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T19:53:26.833+0000] {standard_task_runner.py:57} INFO - Started process 3559 to run task
[2024-01-03T19:53:26.837+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '24', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmp2jx1p2jt']
[2024-01-03T19:53:26.841+0000] {standard_task_runner.py:85} INFO - Job 24: Subtask load_data
[2024-01-03T19:53:26.930+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509
[2024-01-03T19:53:26.933+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data'
[2024-01-03T19:53:26.936+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 7bf68de21308
[2024-01-03T19:53:27.301+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T19:53:27.325+0000] {base.py:73} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-01-03T19:53:27.448+0000] {taskinstance.py:1943} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 221, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag_with_postgres_operator.py", line 99, in load_data
    cursor.execute(query, tuple(row_dict.values()))
psycopg2.errors.NumericValueOutOfRange: integer out of range

[2024-01-03T19:53:27.466+0000] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=booking_ingestion, task_id=load_data, execution_date=20240102T000000, start_date=20240103T195326, end_date=20240103T195327
[2024-01-03T19:53:27.510+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 24 for task load_data (integer out of range
; 3559)
[2024-01-03T19:53:27.532+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2024-01-03T19:53:27.565+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-03T19:59:42.175+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509
[2024-01-03T19:59:42.176+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data'
[2024-01-03T19:59:42.241+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509
[2024-01-03T19:59:42.242+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data'
[2024-01-03T19:59:42.302+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T19:59:42.319+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T19:59:42.320+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T19:59:42.374+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T19:59:42.382+0000] {standard_task_runner.py:57} INFO - Started process 3758 to run task
[2024-01-03T19:59:42.388+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '28', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmp7g8mzgit']
[2024-01-03T19:59:42.391+0000] {standard_task_runner.py:85} INFO - Job 28: Subtask load_data
[2024-01-03T19:59:42.485+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509
[2024-01-03T19:59:42.486+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data'
[2024-01-03T19:59:42.488+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 7bf68de21308
[2024-01-03T19:59:47.072+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T19:59:47.115+0000] {base.py:73} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-01-03T19:59:47.260+0000] {taskinstance.py:1943} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 221, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag_with_postgres_operator.py", line 99, in load_data
    cursor.execute(query, tuple(row_dict.values()))
psycopg2.errors.NumericValueOutOfRange: integer out of range

[2024-01-03T19:59:47.280+0000] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=booking_ingestion, task_id=load_data, execution_date=20240102T000000, start_date=20240103T195942, end_date=20240103T195947
[2024-01-03T19:59:47.378+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 28 for task load_data (integer out of range
; 3758)
[2024-01-03T19:59:47.426+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2024-01-03T19:59:47.456+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-03T20:03:37.455+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509
[2024-01-03T20:03:37.456+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data'
[2024-01-03T20:03:37.511+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509
[2024-01-03T20:03:37.512+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data'
[2024-01-03T20:03:37.563+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T20:03:37.575+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T20:03:37.576+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T20:03:37.621+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T20:03:37.638+0000] {standard_task_runner.py:57} INFO - Started process 3884 to run task
[2024-01-03T20:03:37.643+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '31', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmpbz0p4bt3']
[2024-01-03T20:03:37.649+0000] {standard_task_runner.py:85} INFO - Job 31: Subtask load_data
[2024-01-03T20:03:37.745+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509
[2024-01-03T20:03:37.747+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data'
[2024-01-03T20:03:37.750+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 7bf68de21308
[2024-01-03T20:03:38.142+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T20:03:38.165+0000] {base.py:73} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-01-03T20:03:38.209+0000] {taskinstance.py:1943} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/opt/airflow/dags/dag_with_postgres_operator.py", line 100, in load_data
    cursor.execute(query, tuple(row_dict.values()))
psycopg2.errors.NumericValueOutOfRange: integer out of range


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 221, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag_with_postgres_operator.py", line 101, in load_data
    except psycopg2.Error as e:
NameError: name 'psycopg2' is not defined
[2024-01-03T20:03:38.234+0000] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=booking_ingestion, task_id=load_data, execution_date=20240102T000000, start_date=20240103T200337, end_date=20240103T200338
[2024-01-03T20:03:38.289+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 31 for task load_data (name 'psycopg2' is not defined; 3884)
[2024-01-03T20:03:38.347+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2024-01-03T20:03:38.385+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-03T20:05:15.571+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509
[2024-01-03T20:05:15.572+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data'
[2024-01-03T20:05:15.623+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509
[2024-01-03T20:05:15.623+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data'
[2024-01-03T20:05:15.687+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T20:05:15.701+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T20:05:15.702+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T20:05:15.737+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T20:05:15.744+0000] {standard_task_runner.py:57} INFO - Started process 3937 to run task
[2024-01-03T20:05:15.751+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '34', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmpm688jr5j']
[2024-01-03T20:05:15.754+0000] {standard_task_runner.py:85} INFO - Job 34: Subtask load_data
[2024-01-03T20:05:15.851+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509
[2024-01-03T20:05:15.852+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data'
[2024-01-03T20:05:15.855+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 7bf68de21308
[2024-01-03T20:05:16.236+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T20:05:16.260+0000] {base.py:73} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-01-03T20:05:16.304+0000] {logging_mixin.py:151} INFO - Error: integer out of range
[2024-01-03T20:05:16.305+0000] {logging_mixin.py:151} INFO - Problematic values: dict_values([1, '2018-03-20', 'balcony_2_bed', 1, 2740.0, 'GBP', nan, 'Ann', 'standard', 'Astro Resort'])
[2024-01-03T20:05:16.309+0000] {logging_mixin.py:151} INFO - Error: current transaction is aborted, commands ignored until end of transaction block
[2024-01-03T20:05:16.310+0000] {logging_mixin.py:151} INFO - Problematic values: dict_values([5, '2021-08-07', 'standard_1_bed', 1, 2910.0, 'GBP', 49.0, 'Caroline', 'standard', 'Astro Resort'])
[2024-01-03T20:05:16.317+0000] {logging_mixin.py:151} INFO - Error: current transaction is aborted, commands ignored until end of transaction block
[2024-01-03T20:05:16.318+0000] {logging_mixin.py:151} INFO - Problematic values: dict_values([2, '2017-07-13', 'balcony_2_bed', 2, 1860.0, 'GBP', 38.0, 'Ben', 'standard', 'Dream Connect'])
[2024-01-03T20:05:16.324+0000] {logging_mixin.py:151} INFO - Error: current transaction is aborted, commands ignored until end of transaction block
[2024-01-03T20:05:16.325+0000] {logging_mixin.py:151} INFO - Problematic values: dict_values([6, '2019-09-14', 'first_class_2_bed', 2, 1840.0, 'GBP', 28.0, 'Kate', 'VIP', 'Dream Connect'])
[2024-01-03T20:05:16.329+0000] {logging_mixin.py:151} INFO - Error: current transaction is aborted, commands ignored until end of transaction block
[2024-01-03T20:05:16.333+0000] {logging_mixin.py:151} INFO - Problematic values: dict_values([7, '2022-03-12', 'first_class_2_bed', 2, 1848.6400000000003, 'GBP', 25.0, 'Vishal', 'VIP', 'Dream Connect'])
[2024-01-03T20:05:16.338+0000] {logging_mixin.py:151} INFO - Error: current transaction is aborted, commands ignored until end of transaction block
[2024-01-03T20:05:16.340+0000] {logging_mixin.py:151} INFO - Problematic values: dict_values([2, '2019-10-10', 'standard_2_bed', 5, 1760.0, 'GBP', 38.0, 'Ben', 'standard', 'The Clift Royal'])
[2024-01-03T20:05:16.357+0000] {logging_mixin.py:151} INFO - Error: current transaction is aborted, commands ignored until end of transaction block
[2024-01-03T20:05:16.359+0000] {logging_mixin.py:151} INFO - Problematic values: dict_values([3, '2018-01-16', 'standard_1_bed', 4, nan, nan, 30.0, 'Tom', 'standard', 'Millennium Times Square'])
[2024-01-03T20:05:16.363+0000] {logging_mixin.py:151} INFO - Error: current transaction is aborted, commands ignored until end of transaction block
[2024-01-03T20:05:16.367+0000] {logging_mixin.py:151} INFO - Problematic values: dict_values([5, '2019-12-24', 'standard_2_bed', 3, 4000.0, 'GBP', 49.0, 'Caroline', 'standard', 'Green Acres'])
[2024-01-03T20:05:16.375+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T20:05:16.396+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=load_data, execution_date=20240102T000000, start_date=20240103T200515, end_date=20240103T200516
[2024-01-03T20:05:16.486+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T20:05:16.521+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T20:11:15.010+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509
[2024-01-03T20:11:15.011+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data'
[2024-01-03T20:11:15.066+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509
[2024-01-03T20:11:15.066+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data'
[2024-01-03T20:11:15.118+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T20:11:15.134+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T20:11:15.135+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T20:11:15.181+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T20:11:15.210+0000] {standard_task_runner.py:57} INFO - Started process 4114 to run task
[2024-01-03T20:11:15.214+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '38', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmpsn_0e_ke']
[2024-01-03T20:11:15.218+0000] {standard_task_runner.py:85} INFO - Job 38: Subtask load_data
[2024-01-03T20:11:15.301+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509
[2024-01-03T20:11:15.302+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data'
[2024-01-03T20:11:15.304+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 7bf68de21308
[2024-01-03T20:11:15.648+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T20:11:15.670+0000] {base.py:73} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-01-03T20:11:15.787+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T20:11:15.801+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=load_data, execution_date=20240102T000000, start_date=20240103T201115, end_date=20240103T201115
[2024-01-03T20:11:15.874+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T20:11:15.901+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-03T20:17:27.670+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509
[2024-01-03T20:17:27.671+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data'
[2024-01-03T20:17:27.728+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509
[2024-01-03T20:17:27.731+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data'
[2024-01-03T20:17:27.778+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T20:17:27.794+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [queued]>
[2024-01-03T20:17:27.794+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 6
[2024-01-03T20:17:27.831+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-02 00:00:00+00:00
[2024-01-03T20:17:27.839+0000] {standard_task_runner.py:57} INFO - Started process 4312 to run task
[2024-01-03T20:17:27.844+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-02T00:00:00+00:00', '--job-id', '42', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgres_operator.py', '--cfg-path', '/tmp/tmph1_31dul']
[2024-01-03T20:17:27.849+0000] {standard_task_runner.py:85} INFO - Job 42: Subtask load_data
[2024-01-03T20:17:27.940+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509
[2024-01-03T20:17:27.941+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=booking_ingestion/run_id=scheduled__2024-01-02T00:00:00+00:00/task_id=load_data'
[2024-01-03T20:17:27.944+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-02T00:00:00+00:00 [running]> on host 7bf68de21308
[2024-01-03T20:17:28.319+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-02T00:00:00+00:00'
[2024-01-03T20:17:28.397+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-03T20:17:28.411+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=load_data, execution_date=20240102T000000, start_date=20240103T201727, end_date=20240103T201728
[2024-01-03T20:17:28.459+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-03T20:17:28.490+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
