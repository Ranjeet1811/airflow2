[2024-01-03T02:22:58.285+0000] {processor.py:157} INFO - Started process (PID=184) to work on /opt/airflow/dags/dag_with_postgress_operator2.py
[2024-01-03T02:22:58.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dag_with_postgress_operator2.py for tasks to queue
[2024-01-03T02:22:58.292+0000] {logging_mixin.py:151} INFO - [2024-01-03T02:22:58.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dag_with_postgress_operator2.py
[2024-01-03T02:23:28.431+0000] {logging_mixin.py:151} INFO - [2024-01-03T02:23:28.428+0000] {timeout.py:68} ERROR - Process timed out, PID: 184
[2024-01-03T02:23:28.634+0000] {logging_mixin.py:151} INFO - [2024-01-03T02:23:28.433+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/dag_with_postgress_operator2.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_with_postgress_operator2.py", line 11, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/__init__.py", line 141, in <module>
    from pandas.io.api import (
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/api.py", line 6, in <module>
    from pandas.io.excel import (
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/excel/__init__.py", line 1, in <module>
    from pandas.io.excel._base import (
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/excel/_base.py", line 29, in <module>
    from pandas._libs.parsers import STR_NA_VALUES
  File "<frozen importlib._bootstrap>", line 389, in parent
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/dag_with_postgress_operator2.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.7.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.7.0/best-practices.html#reducing-dag-complexity, PID: 184
[2024-01-03T02:23:28.635+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_with_postgress_operator2.py
[2024-01-03T02:23:28.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_with_postgress_operator2.py took 30.512 seconds
[2024-01-03T02:23:59.282+0000] {processor.py:157} INFO - Started process (PID=223) to work on /opt/airflow/dags/dag_with_postgress_operator2.py
[2024-01-03T02:23:59.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dag_with_postgress_operator2.py for tasks to queue
[2024-01-03T02:23:59.286+0000] {logging_mixin.py:151} INFO - [2024-01-03T02:23:59.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dag_with_postgress_operator2.py
[2024-01-03T02:24:00.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['booking_ingestion']) retrieved from /opt/airflow/dags/dag_with_postgress_operator2.py
[2024-01-03T02:24:04.670+0000] {logging_mixin.py:151} INFO - [2024-01-03T02:24:04.669+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2024-01-03T02:24:04.724+0000] {logging_mixin.py:151} INFO - [2024-01-03T02:24:04.723+0000] {dag.py:3677} INFO - Setting next_dagrun for booking_ingestion to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T02:24:04.758+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 314, in iter
    return fut.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 3079, in bulk_write_to_db
    session.flush()  # this is required to ensure each dataset has its PK loaded
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3589, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/persistence.py", line 237, in save_obj
    _emit_update_statements(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/persistence.py", line 1035, in _emit_update_statements
    raise orm_exc.StaleDataError(
sqlalchemy.orm.exc.StaleDataError: UPDATE statement on table 'serialized_dag' expected to update 1 row(s); 0 were matched.
[2024-01-03T02:24:35.945+0000] {processor.py:157} INFO - Started process (PID=248) to work on /opt/airflow/dags/dag_with_postgress_operator2.py
[2024-01-03T02:24:35.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dag_with_postgress_operator2.py for tasks to queue
[2024-01-03T02:24:35.958+0000] {logging_mixin.py:151} INFO - [2024-01-03T02:24:35.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dag_with_postgress_operator2.py
[2024-01-03T02:24:37.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['booking_ingestion']) retrieved from /opt/airflow/dags/dag_with_postgress_operator2.py
[2024-01-03T02:24:37.605+0000] {logging_mixin.py:151} INFO - [2024-01-03T02:24:37.604+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2024-01-03T02:24:37.650+0000] {logging_mixin.py:151} INFO - [2024-01-03T02:24:37.650+0000] {dag.py:3677} INFO - Setting next_dagrun for booking_ingestion to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T02:24:38.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_with_postgress_operator2.py took 2.082 seconds
[2024-01-03T02:25:08.558+0000] {processor.py:157} INFO - Started process (PID=267) to work on /opt/airflow/dags/dag_with_postgress_operator2.py
[2024-01-03T02:25:08.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/dag_with_postgress_operator2.py for tasks to queue
[2024-01-03T02:25:08.562+0000] {logging_mixin.py:151} INFO - [2024-01-03T02:25:08.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/dag_with_postgress_operator2.py
[2024-01-03T02:25:09.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['booking_ingestion']) retrieved from /opt/airflow/dags/dag_with_postgress_operator2.py
[2024-01-03T02:25:09.671+0000] {logging_mixin.py:151} INFO - [2024-01-03T02:25:09.670+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2024-01-03T02:25:09.726+0000] {logging_mixin.py:151} INFO - [2024-01-03T02:25:09.726+0000] {dag.py:3677} INFO - Setting next_dagrun for booking_ingestion to 2024-01-03T00:00:00+00:00, run_after=2024-01-04T00:00:00+00:00
[2024-01-03T02:25:10.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_with_postgress_operator2.py took 1.713 seconds
