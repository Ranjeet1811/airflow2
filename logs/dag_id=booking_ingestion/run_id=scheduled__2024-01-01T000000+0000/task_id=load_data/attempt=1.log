[2024-01-02T20:57:08.737+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T20:57:08.760+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T20:57:08.762+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-02T20:57:08.815+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-01 00:00:00+00:00
[2024-01-02T20:57:08.823+0000] {standard_task_runner.py:57} INFO - Started process 429 to run task
[2024-01-02T20:57:08.828+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-01T00:00:00+00:00', '--job-id', '28', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator2.py', '--cfg-path', '/tmp/tmp9e6h6raf']
[2024-01-02T20:57:08.833+0000] {standard_task_runner.py:85} INFO - Job 28: Subtask load_data
[2024-01-02T20:57:08.933+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-02T20:57:09.223+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-01T00:00:00+00:00'
[2024-01-02T20:57:09.550+0000] {base.py:73} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-01-02T20:57:10.071+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgress_operator2.py:78 UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
[2024-01-02T20:57:10.081+0000] {taskinstance.py:1943} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2202, in execute
    cur.execute(sql, *args)
psycopg2.errors.UndefinedTable: relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 221, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag_with_postgress_operator2.py", line 78, in load_data
    records.to_sql('booking_record', conn, if_exists='replace', index=False)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 2878, in to_sql
    return sql.to_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 769, in to_sql
    return pandas_sql.to_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2378, in to_sql
    table.create()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 903, in create
    if self.exists():
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 889, in exists
    return self.pd_sql.has_table(self.name, self.schema)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2385, in has_table
    return len(self.execute(query, [name]).fetchall()) > 0
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2214, in execute
    raise ex from exc
pandas.errors.DatabaseError: Execution failed on sql 'SELECT name FROM sqlite_master WHERE type='table' AND name=?;': relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^

[2024-01-02T20:57:10.104+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=booking_ingestion, task_id=load_data, execution_date=20240101T000000, start_date=20240102T205708, end_date=20240102T205710
[2024-01-02T20:57:10.177+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 28 for task load_data (Execution failed on sql 'SELECT name FROM sqlite_master WHERE type='table' AND name=?;': relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^
; 429)
[2024-01-02T20:57:10.210+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2024-01-02T20:57:10.251+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-02T21:04:04.610+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T21:04:04.665+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T21:04:04.666+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-02T21:04:04.715+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-01 00:00:00+00:00
[2024-01-02T21:04:04.733+0000] {standard_task_runner.py:57} INFO - Started process 713 to run task
[2024-01-02T21:04:04.754+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-01T00:00:00+00:00', '--job-id', '30', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator2.py', '--cfg-path', '/tmp/tmp8tbercjp']
[2024-01-02T21:04:04.769+0000] {standard_task_runner.py:85} INFO - Job 30: Subtask load_data
[2024-01-02T21:04:04.918+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-02T21:04:05.328+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-01T00:00:00+00:00'
[2024-01-02T21:04:05.669+0000] {base.py:73} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-01-02T21:04:05.702+0000] {taskinstance.py:1943} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 221, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag_with_postgress_operator2.py", line 63, in load_data
    cursor.execute('''
psycopg2.errors.SyntaxError: type modifier is not allowed for type "text"
LINE 5:                         room_type TEXT(512) NOT NULL,
                                          ^

[2024-01-02T21:04:05.729+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=booking_ingestion, task_id=load_data, execution_date=20240101T000000, start_date=20240102T210404, end_date=20240102T210405
[2024-01-02T21:04:05.803+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 30 for task load_data (type modifier is not allowed for type "text"
LINE 5:                         room_type TEXT(512) NOT NULL,
                                          ^
; 713)
[2024-01-02T21:04:05.849+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2024-01-02T21:04:05.886+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-02T21:10:20.456+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T21:10:20.469+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T21:10:20.470+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-02T21:10:20.541+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-01 00:00:00+00:00
[2024-01-02T21:10:20.548+0000] {standard_task_runner.py:57} INFO - Started process 958 to run task
[2024-01-02T21:10:20.553+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-01T00:00:00+00:00', '--job-id', '32', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator2.py', '--cfg-path', '/tmp/tmp9g39gonu']
[2024-01-02T21:10:20.557+0000] {standard_task_runner.py:85} INFO - Job 32: Subtask load_data
[2024-01-02T21:10:20.699+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-02T21:10:20.925+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-01T00:00:00+00:00'
[2024-01-02T21:10:21.312+0000] {base.py:73} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-01-02T21:10:21.772+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgress_operator2.py:78 UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
[2024-01-02T21:10:21.807+0000] {taskinstance.py:1943} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2202, in execute
    cur.execute(sql, *args)
psycopg2.errors.UndefinedTable: relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 221, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag_with_postgress_operator2.py", line 78, in load_data
    records.to_sql('booking_record', conn, if_exists='replace', index=False)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 2878, in to_sql
    return sql.to_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 769, in to_sql
    return pandas_sql.to_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2378, in to_sql
    table.create()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 903, in create
    if self.exists():
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 889, in exists
    return self.pd_sql.has_table(self.name, self.schema)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2385, in has_table
    return len(self.execute(query, [name]).fetchall()) > 0
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2214, in execute
    raise ex from exc
pandas.errors.DatabaseError: Execution failed on sql 'SELECT name FROM sqlite_master WHERE type='table' AND name=?;': relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^

[2024-01-02T21:10:21.998+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=booking_ingestion, task_id=load_data, execution_date=20240101T000000, start_date=20240102T211020, end_date=20240102T211021
[2024-01-02T21:10:22.167+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 32 for task load_data (Execution failed on sql 'SELECT name FROM sqlite_master WHERE type='table' AND name=?;': relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^
; 958)
[2024-01-02T21:10:22.230+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2024-01-02T21:10:22.316+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-02T21:11:42.201+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T21:11:42.218+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T21:11:42.219+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-02T21:11:42.289+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-01 00:00:00+00:00
[2024-01-02T21:11:42.298+0000] {standard_task_runner.py:57} INFO - Started process 1034 to run task
[2024-01-02T21:11:42.303+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-01T00:00:00+00:00', '--job-id', '34', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator2.py', '--cfg-path', '/tmp/tmpyfpvrvcp']
[2024-01-02T21:11:42.308+0000] {standard_task_runner.py:85} INFO - Job 34: Subtask load_data
[2024-01-02T21:11:42.433+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-02T21:11:42.602+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-01T00:00:00+00:00'
[2024-01-02T21:11:42.852+0000] {base.py:73} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-01-02T21:11:42.908+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgress_operator2.py:78 UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
[2024-01-02T21:11:42.917+0000] {taskinstance.py:1943} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2202, in execute
    cur.execute(sql, *args)
psycopg2.errors.UndefinedTable: relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 221, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag_with_postgress_operator2.py", line 78, in load_data
    records.to_sql('booking_record', conn, if_exists='replace', index=False)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 2878, in to_sql
    return sql.to_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 769, in to_sql
    return pandas_sql.to_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2378, in to_sql
    table.create()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 903, in create
    if self.exists():
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 889, in exists
    return self.pd_sql.has_table(self.name, self.schema)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2385, in has_table
    return len(self.execute(query, [name]).fetchall()) > 0
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2214, in execute
    raise ex from exc
pandas.errors.DatabaseError: Execution failed on sql 'SELECT name FROM sqlite_master WHERE type='table' AND name=?;': relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^

[2024-01-02T21:11:42.937+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=booking_ingestion, task_id=load_data, execution_date=20240101T000000, start_date=20240102T211142, end_date=20240102T211142
[2024-01-02T21:11:42.974+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 34 for task load_data (Execution failed on sql 'SELECT name FROM sqlite_master WHERE type='table' AND name=?;': relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^
; 1034)
[2024-01-02T21:11:43.000+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2024-01-02T21:11:43.056+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-02T21:32:15.340+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T21:32:15.362+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T21:32:15.363+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-02T21:32:15.404+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-01 00:00:00+00:00
[2024-01-02T21:32:15.412+0000] {standard_task_runner.py:57} INFO - Started process 1840 to run task
[2024-01-02T21:32:15.417+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-01T00:00:00+00:00', '--job-id', '36', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator2.py', '--cfg-path', '/tmp/tmpgedwy3fh']
[2024-01-02T21:32:15.421+0000] {standard_task_runner.py:85} INFO - Job 36: Subtask load_data
[2024-01-02T21:32:15.517+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-02T21:32:15.712+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-01T00:00:00+00:00'
[2024-01-02T21:32:16.040+0000] {base.py:73} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-01-02T21:32:16.239+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-02T21:32:16.256+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=load_data, execution_date=20240101T000000, start_date=20240102T213215, end_date=20240102T213216
[2024-01-02T21:32:16.416+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-02T21:32:16.481+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-02T21:38:11.347+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T21:38:11.360+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T21:38:11.360+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-02T21:38:11.402+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-01 00:00:00+00:00
[2024-01-02T21:38:11.410+0000] {standard_task_runner.py:57} INFO - Started process 2078 to run task
[2024-01-02T21:38:11.414+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-01T00:00:00+00:00', '--job-id', '39', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator2.py', '--cfg-path', '/tmp/tmpdvjg8717']
[2024-01-02T21:38:11.417+0000] {standard_task_runner.py:85} INFO - Job 39: Subtask load_data
[2024-01-02T21:38:11.499+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-02T21:38:11.667+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-01T00:00:00+00:00'
[2024-01-02T21:38:11.919+0000] {base.py:73} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-01-02T21:38:11.944+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-02T21:38:11.960+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=load_data, execution_date=20240101T000000, start_date=20240102T213811, end_date=20240102T213811
[2024-01-02T21:38:12.028+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-02T21:38:12.059+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-02T21:44:20.561+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T21:44:20.589+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T21:44:20.590+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-02T21:44:20.666+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-01 00:00:00+00:00
[2024-01-02T21:44:20.674+0000] {standard_task_runner.py:57} INFO - Started process 2351 to run task
[2024-01-02T21:44:20.698+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-01T00:00:00+00:00', '--job-id', '42', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator2.py', '--cfg-path', '/tmp/tmpfcl_xgsz']
[2024-01-02T21:44:20.702+0000] {standard_task_runner.py:85} INFO - Job 42: Subtask load_data
[2024-01-02T21:44:20.839+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-02T21:44:21.036+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-01T00:00:00+00:00'
[2024-01-02T21:44:21.250+0000] {base.py:73} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-01-02T21:44:21.271+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-02T21:44:21.289+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=load_data, execution_date=20240101T000000, start_date=20240102T214420, end_date=20240102T214421
[2024-01-02T21:44:21.393+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-02T21:44:21.431+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-02T22:01:35.706+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T22:01:35.785+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T22:01:35.786+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-02T22:01:35.842+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-01 00:00:00+00:00
[2024-01-02T22:01:35.849+0000] {standard_task_runner.py:57} INFO - Started process 3026 to run task
[2024-01-02T22:01:35.854+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-01T00:00:00+00:00', '--job-id', '45', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator2.py', '--cfg-path', '/tmp/tmpjbd070ig']
[2024-01-02T22:01:35.857+0000] {standard_task_runner.py:85} INFO - Job 45: Subtask load_data
[2024-01-02T22:01:36.029+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-02T22:01:36.232+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-01T00:00:00+00:00'
[2024-01-02T22:01:36.509+0000] {base.py:73} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-01-02T22:01:37.548+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-02T22:01:37.575+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=load_data, execution_date=20240101T000000, start_date=20240102T220135, end_date=20240102T220137
[2024-01-02T22:01:37.716+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-02T22:01:37.749+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-01-02T22:05:42.861+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T22:05:42.897+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T22:05:42.899+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-02T22:05:43.002+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-01 00:00:00+00:00
[2024-01-02T22:05:43.022+0000] {standard_task_runner.py:57} INFO - Started process 3207 to run task
[2024-01-02T22:05:43.036+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-01T00:00:00+00:00', '--job-id', '48', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator2.py', '--cfg-path', '/tmp/tmp8kaudbsw']
[2024-01-02T22:05:43.041+0000] {standard_task_runner.py:85} INFO - Job 48: Subtask load_data
[2024-01-02T22:05:43.176+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-02T22:05:43.636+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-01T00:00:00+00:00'
[2024-01-02T22:05:43.955+0000] {base.py:73} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-01-02T22:05:44.431+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgress_operator2.py:78 UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
[2024-01-02T22:05:44.466+0000] {taskinstance.py:1943} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2202, in execute
    cur.execute(sql, *args)
psycopg2.errors.UndefinedTable: relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 221, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag_with_postgress_operator2.py", line 78, in load_data
    records.to_sql('booking_record', conn, if_exists='replace', index=False)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 2878, in to_sql
    return sql.to_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 769, in to_sql
    return pandas_sql.to_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2378, in to_sql
    table.create()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 903, in create
    if self.exists():
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 889, in exists
    return self.pd_sql.has_table(self.name, self.schema)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2385, in has_table
    return len(self.execute(query, [name]).fetchall()) > 0
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2214, in execute
    raise ex from exc
pandas.errors.DatabaseError: Execution failed on sql 'SELECT name FROM sqlite_master WHERE type='table' AND name=?;': relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^

[2024-01-02T22:05:44.710+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=booking_ingestion, task_id=load_data, execution_date=20240101T000000, start_date=20240102T220542, end_date=20240102T220544
[2024-01-02T22:05:45.265+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 48 for task load_data (Execution failed on sql 'SELECT name FROM sqlite_master WHERE type='table' AND name=?;': relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^
; 3207)
[2024-01-02T22:05:45.299+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2024-01-02T22:05:45.342+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-02T22:19:12.046+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T22:19:12.113+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T22:19:12.114+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-02T22:19:13.221+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-01 00:00:00+00:00
[2024-01-02T22:19:13.230+0000] {standard_task_runner.py:57} INFO - Started process 3722 to run task
[2024-01-02T22:19:13.235+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-01T00:00:00+00:00', '--job-id', '50', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator2.py', '--cfg-path', '/tmp/tmp5jvy8rw3']
[2024-01-02T22:19:13.241+0000] {standard_task_runner.py:85} INFO - Job 50: Subtask load_data
[2024-01-02T22:19:13.402+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-02T22:19:13.580+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-01T00:00:00+00:00'
[2024-01-02T22:19:13.967+0000] {base.py:73} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-01-02T22:19:14.089+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgress_operator2.py:78 UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
[2024-01-02T22:19:14.102+0000] {taskinstance.py:1943} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2202, in execute
    cur.execute(sql, *args)
psycopg2.errors.UndefinedTable: relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 221, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag_with_postgress_operator2.py", line 78, in load_data
    records.to_sql('booking_record', con=conn, if_exists='replace', index=False)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 2878, in to_sql
    return sql.to_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 769, in to_sql
    return pandas_sql.to_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2378, in to_sql
    table.create()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 903, in create
    if self.exists():
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 889, in exists
    return self.pd_sql.has_table(self.name, self.schema)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2385, in has_table
    return len(self.execute(query, [name]).fetchall()) > 0
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2214, in execute
    raise ex from exc
pandas.errors.DatabaseError: Execution failed on sql 'SELECT name FROM sqlite_master WHERE type='table' AND name=?;': relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^

[2024-01-02T22:19:14.135+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=booking_ingestion, task_id=load_data, execution_date=20240101T000000, start_date=20240102T221912, end_date=20240102T221914
[2024-01-02T22:19:14.191+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 50 for task load_data (Execution failed on sql 'SELECT name FROM sqlite_master WHERE type='table' AND name=?;': relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^
; 3722)
[2024-01-02T22:19:14.254+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2024-01-02T22:19:14.348+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-02T22:24:31.220+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T22:24:31.235+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T22:24:31.236+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-02T22:24:31.277+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-01 00:00:00+00:00
[2024-01-02T22:24:31.285+0000] {standard_task_runner.py:57} INFO - Started process 3956 to run task
[2024-01-02T22:24:31.290+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-01T00:00:00+00:00', '--job-id', '52', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator2.py', '--cfg-path', '/tmp/tmpnyqlwzu1']
[2024-01-02T22:24:31.294+0000] {standard_task_runner.py:85} INFO - Job 52: Subtask load_data
[2024-01-02T22:24:31.394+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-02T22:24:31.568+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-01T00:00:00+00:00'
[2024-01-02T22:24:31.806+0000] {base.py:73} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-01-02T22:24:32.018+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgress_operator2.py:79 UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
[2024-01-02T22:24:32.029+0000] {taskinstance.py:1943} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2202, in execute
    cur.execute(sql, *args)
psycopg2.errors.UndefinedTable: relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 221, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag_with_postgress_operator2.py", line 79, in load_data
    records.to_sql('booking_record', con=conn, if_exists='replace', index=False)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 2878, in to_sql
    return sql.to_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 769, in to_sql
    return pandas_sql.to_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2378, in to_sql
    table.create()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 903, in create
    if self.exists():
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 889, in exists
    return self.pd_sql.has_table(self.name, self.schema)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2385, in has_table
    return len(self.execute(query, [name]).fetchall()) > 0
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2214, in execute
    raise ex from exc
pandas.errors.DatabaseError: Execution failed on sql 'SELECT name FROM sqlite_master WHERE type='table' AND name=?;': relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^

[2024-01-02T22:24:32.074+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=booking_ingestion, task_id=load_data, execution_date=20240101T000000, start_date=20240102T222431, end_date=20240102T222432
[2024-01-02T22:24:32.151+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 52 for task load_data (Execution failed on sql 'SELECT name FROM sqlite_master WHERE type='table' AND name=?;': relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^
; 3956)
[2024-01-02T22:24:32.186+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2024-01-02T22:24:32.223+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-02T22:25:48.690+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T22:25:48.708+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T22:25:48.709+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-02T22:25:48.753+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-01 00:00:00+00:00
[2024-01-02T22:25:48.761+0000] {standard_task_runner.py:57} INFO - Started process 4024 to run task
[2024-01-02T22:25:48.765+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-01T00:00:00+00:00', '--job-id', '54', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator2.py', '--cfg-path', '/tmp/tmpfghz17w8']
[2024-01-02T22:25:48.770+0000] {standard_task_runner.py:85} INFO - Job 54: Subtask load_data
[2024-01-02T22:25:48.866+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-02T22:25:49.006+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-01T00:00:00+00:00'
[2024-01-02T22:25:49.268+0000] {base.py:73} INFO - Using connection ID 'postgres_localhost' for task execution.
[2024-01-02T22:25:49.315+0000] {logging_mixin.py:151} WARNING - /opt/***/dags/dag_with_postgress_operator2.py:79 UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
[2024-01-02T22:25:49.327+0000] {taskinstance.py:1943} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2202, in execute
    cur.execute(sql, *args)
psycopg2.errors.UndefinedTable: relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 221, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag_with_postgress_operator2.py", line 79, in load_data
    records.to_sql('booking_record', con=conn, if_exists='replace', index=False)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 2878, in to_sql
    return sql.to_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 769, in to_sql
    return pandas_sql.to_sql(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2378, in to_sql
    table.create()
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 903, in create
    if self.exists():
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 889, in exists
    return self.pd_sql.has_table(self.name, self.schema)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2385, in has_table
    return len(self.execute(query, [name]).fetchall()) > 0
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/io/sql.py", line 2214, in execute
    raise ex from exc
pandas.errors.DatabaseError: Execution failed on sql 'SELECT name FROM sqlite_master WHERE type='table' AND name=?;': relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^

[2024-01-02T22:25:49.351+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=booking_ingestion, task_id=load_data, execution_date=20240101T000000, start_date=20240102T222548, end_date=20240102T222549
[2024-01-02T22:25:49.417+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 54 for task load_data (Execution failed on sql 'SELECT name FROM sqlite_master WHERE type='table' AND name=?;': relation "sqlite_master" does not exist
LINE 1: SELECT name FROM sqlite_master WHERE type='table' AND name=?...
                         ^
; 4024)
[2024-01-02T22:25:49.460+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2024-01-02T22:25:49.492+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-02T22:42:53.527+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T22:42:53.569+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [queued]>
[2024-01-02T22:42:53.581+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-01-02T22:42:53.697+0000] {taskinstance.py:1382} INFO - Executing <Task(_PythonDecoratedOperator): load_data> on 2024-01-01 00:00:00+00:00
[2024-01-02T22:42:53.704+0000] {standard_task_runner.py:57} INFO - Started process 4729 to run task
[2024-01-02T22:42:53.709+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'booking_ingestion', 'load_data', 'scheduled__2024-01-01T00:00:00+00:00', '--job-id', '57', '--raw', '--subdir', 'DAGS_FOLDER/dag_with_postgress_operator2.py', '--cfg-path', '/tmp/tmptif8tu7y']
[2024-01-02T22:42:53.713+0000] {standard_task_runner.py:85} INFO - Job 57: Subtask load_data
[2024-01-02T22:42:53.816+0000] {task_command.py:415} INFO - Running <TaskInstance: booking_ingestion.load_data scheduled__2024-01-01T00:00:00+00:00 [running]> on host 2590655a4ba7
[2024-01-02T22:42:54.029+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='booking_ingestion' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2024-01-01T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-01T00:00:00+00:00'
[2024-01-02T22:42:54.616+0000] {python.py:194} INFO - Done. Returned value was: None
[2024-01-02T22:42:54.634+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=booking_ingestion, task_id=load_data, execution_date=20240101T000000, start_date=20240102T224253, end_date=20240102T224254
[2024-01-02T22:42:54.686+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-01-02T22:42:54.718+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
